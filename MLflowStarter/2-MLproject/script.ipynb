{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc585327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "246763ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7a67802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dee9bfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 15:14:37.708046: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-03 15:14:37.988478: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-03 15:14:39.665438: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-03 15:14:40.673846: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746263681.519590 1502352 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746263681.730018 1502352 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746263683.527721 1502352 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746263683.527783 1502352 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746263683.527789 1502352 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746263683.527793 1502352 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-03 15:14:43.668412: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/saif/New Volume/GenomeArcDev/MLOps/MLops/venv/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.29.4 is exactly one major version older than the runtime version 6.30.2 at google/protobuf/any.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/saif/New Volume/GenomeArcDev/MLOps/MLops/venv/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.29.4 is exactly one major version older than the runtime version 6.30.2 at google/protobuf/wrappers.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "from hyperopt import STATUS_OK,Trials,fmin,hp,tpe\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b003e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d598705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6ab213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the data into training, validation and test set\n",
    "train,test = train_test_split(data,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "507910df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop(['quality'],axis=1).values\n",
    "train_y = train[['quality']].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d627f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test.drop(['quality'],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8b3c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test[['quality']].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af7aa41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,valid_x,train_y,valid_y = train_test_split(train_x,train_y,test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9aadc513",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature = infer_signature(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3bcd0572",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANN Model\n",
    "\n",
    "def train_model(params,epochs,train_x,train_y,valid_x,valid_y,test_x,test_y):\n",
    "\n",
    "    ## Define model architecture\n",
    "    mean=np.mean(train_x,axis=0)\n",
    "    var=np.var(train_x,axis=0)\n",
    "\n",
    "    model=keras.Sequential(\n",
    "        [\n",
    "            keras.Input([train_x.shape[1]]),\n",
    "            keras.layers.Normalization(mean=mean,variance=var),\n",
    "            keras.layers.Dense(64,activation='relu'),\n",
    "            keras.layers.Dense(1)\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ## compile the model\n",
    "    model.compile(optimizer=keras.optimizers.SGD(\n",
    "        learning_rate=params[\"lr\"],momentum=params[\"momentum\"]\n",
    "    ),\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "    ## Train the ANN model with lr and momentum params wwith MLFLOW tracking\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model.fit(train_x,train_y,validation_data=(valid_x,valid_y),\n",
    "                  epochs=epochs,\n",
    "                  batch_size=64)\n",
    "        \n",
    "        ## Evaluate the model\n",
    "        eval_result=model.evaluate(valid_x,valid_y,batch_size=64)\n",
    "\n",
    "        eval_rmse=eval_result[1]\n",
    "\n",
    "        ## Log the parameters and results\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"eval_rmse\",eval_rmse)\n",
    "\n",
    "        ## log the model\n",
    "\n",
    "        mlflow.tensorflow.log_model(model,\"model\",signature=signature)\n",
    "\n",
    "        return {\"loss\": eval_rmse, \"status\": STATUS_OK, \"model\": model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b01cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    result = train_model(\n",
    "        params,\n",
    "        epochs=3,\n",
    "        train_x=train_x,\n",
    "        train_y=train_y,\n",
    "        valid_x=valid_x,\n",
    "        valid_y=valid_y,\n",
    "        test_x=test_x,\n",
    "        test_y=test_y\n",
    "\n",
    "    )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8cec0ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "space={\n",
    "    \"lr\":hp.loguniform(\"lr\",np.log(1e-5),np.log(1e-1)),\n",
    "    \"momentum\":hp.uniform(\"momentum\",0.0,1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a80c6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/37\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 299ms/step - loss: 32.2701 - root_mean_squared_error: 5.6807\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 32.1812 - root_mean_squared_error: 5.6723 - val_loss: 26.5249 - val_root_mean_squared_error: 5.1502\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/37\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 26.5883 - root_mean_squared_error: 5.1564\n",
      "\u001b[1m13/37\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.5744 - root_mean_squared_error: 5.1549 \n",
      "\u001b[1m24/37\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25.9801 - root_mean_squared_error: 5.0966\n",
      "\u001b[1m35/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25.4744 - root_mean_squared_error: 5.0463\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 25.3437 - root_mean_squared_error: 5.0332 - val_loss: 20.5596 - val_root_mean_squared_error: 4.5343\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/37\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 21.9928 - root_mean_squared_error: 4.6896\n",
      "\u001b[1m34/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.9452 - root_mean_squared_error: 4.4644 \n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.7966 - root_mean_squared_error: 4.4477 - val_loss: 15.8777 - val_root_mean_squared_error: 3.9847\n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 13.4674 - root_mean_squared_error: 3.6698\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 15.3548 - root_mean_squared_error: 3.9176 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/37\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 415ms/step - loss: 40.4702 - root_mean_squared_error: 6.3616\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 40.2497 - root_mean_squared_error: 6.3439 - val_loss: 37.2529 - val_root_mean_squared_error: 6.1035\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/37\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 38.1770 - root_mean_squared_error: 6.1788\n",
      "\u001b[1m15/37\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.7189 - root_mean_squared_error: 6.0595 \n",
      "\u001b[1m27/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.4542 - root_mean_squared_error: 6.0376\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 36.1651 - root_mean_squared_error: 6.0135 - val_loss: 33.5905 - val_root_mean_squared_error: 5.7957\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/37\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 32.7549 - root_mean_squared_error: 5.7232\n",
      "\u001b[1m11/37\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.7923 - root_mean_squared_error: 5.8129 \n",
      "\u001b[1m23/37\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.4421 - root_mean_squared_error: 5.7827\n",
      "\u001b[1m33/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.1016 - root_mean_squared_error: 5.7531\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 32.9346 - root_mean_squared_error: 5.7385 - val_loss: 30.3276 - val_root_mean_squared_error: 5.5071\n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 28.3958 - root_mean_squared_error: 5.3288\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.9070 - root_mean_squared_error: 5.4685 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/37\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 214ms/step - loss: 44.0924 - root_mean_squared_error: 6.6402\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.0363 - root_mean_squared_error: 3.7208 - val_loss: 1.2459 - val_root_mean_squared_error: 1.1162\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/37\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0685 - root_mean_squared_error: 1.0337\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9656 - root_mean_squared_error: 0.9825 - val_loss: 0.8215 - val_root_mean_squared_error: 0.9064\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/37\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.6250 - root_mean_squared_error: 0.7906\n",
      "\u001b[1m16/37\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7027 - root_mean_squared_error: 0.8379 \n",
      "\u001b[1m28/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7121 - root_mean_squared_error: 0.8436\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.7146 - root_mean_squared_error: 0.8452 - val_loss: 0.7376 - val_root_mean_squared_error: 0.8589\n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6415 - root_mean_squared_error: 0.8009\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7043 - root_mean_squared_error: 0.8389 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/37\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 232ms/step - loss: 35.2955 - root_mean_squared_error: 5.9410\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 35.0869 - root_mean_squared_error: 5.9234 - val_loss: 33.7376 - val_root_mean_squared_error: 5.8084\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/37\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 35.6330 - root_mean_squared_error: 5.9693\n",
      "\u001b[1m10/37\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 35.5513 - root_mean_squared_error: 5.9624 \n",
      "\u001b[1m22/37\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 35.1893 - root_mean_squared_error: 5.9319\n",
      "\u001b[1m34/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 35.0009 - root_mean_squared_error: 5.9160\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 34.9456 - root_mean_squared_error: 5.9114 - val_loss: 33.4249 - val_root_mean_squared_error: 5.7814\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/37\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 33.1184 - root_mean_squared_error: 5.7549\n",
      "\u001b[1m13/37\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.2239 - root_mean_squared_error: 5.8500 \n",
      "\u001b[1m25/37\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 34.1325 - root_mean_squared_error: 5.8422\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 34.1241 - root_mean_squared_error: 5.8415 - val_loss: 33.1155 - val_root_mean_squared_error: 5.7546\n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 31.3916 - root_mean_squared_error: 5.6028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.5439 - root_mean_squared_error: 5.7045 \n",
      "\n",
      "100%|██████████| 4/4 [01:07<00:00, 16.87s/trial, best loss: 0.8588565587997437]\n",
      "Best parameters: {'lr': np.float64(0.00530333071560844), 'momentum': np.float64(0.8828321158569555)}\n",
      "Best eval rmse: 0.8588565587997437\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"wine-quality\")\n",
    "with mlflow.start_run():\n",
    "    # Conduct the hyperparameter search using Hyperopt\n",
    "    trials=Trials()\n",
    "    best=fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=4,\n",
    "        trials=trials\n",
    "    )\n",
    "\n",
    "    # Fetch the details of the best run\n",
    "    best_run = sorted(trials.results, key=lambda x: x[\"loss\"])[0]\n",
    "\n",
    "    # Log the best parameters, loss, and model\n",
    "    mlflow.log_params(best)\n",
    "    mlflow.log_metric(\"eval_rmse\", best_run[\"loss\"])\n",
    "    mlflow.tensorflow.log_model(best_run[\"model\"], \"model\", signature=signature)\n",
    "\n",
    "    # Print out the best parameters and corresponding loss\n",
    "    print(f\"Best parameters: {best}\")\n",
    "    print(f\"Best eval rmse: {best_run['loss']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "df50549d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/03 16:23:43 INFO mlflow.models.python_api: It is highly recommended to use `uv` as the environment manager for predicting with MLflow models as its performance is significantly better than other environment managers. Run `pip install uv` to install uv. See https://docs.astral.sh/uv/getting-started/installation for other installation methods.\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 1390.88it/s] \n",
      "2025/05/03 16:23:43 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "{\"predictions\": [[5.7780303955078125], [7.090057373046875], [6.612865447998047], [5.324977874755859], [6.124493598937988], [6.498795032501221], [5.807153701782227], [5.49308967590332], [6.233182907104492], [5.921135902404785], [7.090582370758057], [4.616716384887695], [6.741005897521973], [5.153820037841797], [7.705026626586914], [5.110430717468262], [7.34281063079834], [6.249259948730469], [6.505252838134766], [5.227218151092529], [5.363917350769043], [6.506011009216309], [4.95101261138916], [5.729887962341309], [5.7222442626953125], [5.133843421936035], [4.728233337402344], [6.220978260040283], [5.614713668823242], [5.223491191864014], [5.472538948059082], [5.444295883178711], [6.142139911651611], [5.193694114685059], [5.494067668914795], [6.843197822570801], [6.930771827697754], [4.872823715209961], [5.26069974899292], [5.958134174346924], [5.835751533508301], [5.318768501281738], [5.570821285247803], [5.9979448318481445], [4.911815166473389], [6.4327592849731445], [5.648777961730957], [5.624502658843994], [5.335679531097412], [5.8213419914245605], [4.941369533538818], [5.932109832763672], [6.241200923919678], [6.103344440460205], [5.901288032531738], [5.864115238189697], [6.217565059661865], [5.653742790222168], [5.645341873168945], [5.674383640289307], [5.658514976501465], [6.658846855163574], [5.026716709136963], [7.405449867248535], [6.220541477203369], [6.501936435699463], [6.302417755126953], [5.794622421264648], [6.023349285125732], [5.211897850036621], [4.829503059387207], [5.84517765045166], [5.131229877471924], [4.670734882354736], [5.709120273590088], [6.4801225662231445], [5.978636741638184], [5.5676679611206055], [8.100615501403809], [6.146113395690918], [5.641256332397461], [5.4256510734558105], [5.693050384521484], [5.020051002502441], [6.375324726104736], [6.478699684143066], [4.949997425079346], [5.920445442199707], [6.643918037414551], [6.170114040374756], [6.505233287811279], [5.328901767730713], [5.27946138381958], [7.345983982086182], [7.00759744644165], [6.9446001052856445], [7.0945892333984375], [5.603221893310547], [4.836858749389648], [7.307640552520752], [5.068422317504883], [6.1562066078186035], [6.54286003112793], [5.149492263793945], [6.462157726287842], [5.860848426818848], [5.674383640289307], [5.963749885559082], [6.249259948730469], [6.062470436096191], [5.840095520019531], [6.415643215179443], [6.8948774337768555], [5.531250953674316], [5.246531963348389], [7.363752841949463], [7.064442157745361], [6.979975700378418], [5.453516483306885], [6.049537181854248], [5.5178022384643555], [7.468642711639404], [6.086987495422363], [5.010016918182373], [5.938440322875977], [6.175817012786865], [7.539731025695801], [5.686647891998291], [6.505223274230957], [5.443824768066406], [5.912332534790039], [5.907835006713867], [5.792630195617676], [6.377676963806152], [5.048724174499512], [6.282415390014648], [5.303372859954834], [5.227972984313965], [6.854882717132568], [4.947248935699463], [7.238121032714844], [5.568524360656738], [6.57094144821167], [5.590207576751709], [5.619688510894775], [5.136961936950684], [4.5510101318359375], [5.270486354827881], [5.537336349487305], [5.02671480178833], [6.988729953765869], [5.702911853790283], [6.4246392250061035], [6.586371898651123], [5.939177989959717], [5.164419174194336], [6.700087547302246], [6.632054328918457], [6.150451183319092], [6.4868292808532715], [5.695384979248047], [5.135328769683838], [6.1751508712768555], [5.6279520988464355], [5.787627220153809], [6.533304214477539], [4.9763336181640625], [5.989274024963379], [5.450444221496582], [5.836893081665039], [4.7056121826171875], [6.214235305786133], [6.342190742492676], [5.594216346740723], [7.24467134475708], [5.563179969787598], [6.102794647216797], [6.105563163757324], [5.8150434494018555], [4.932432651519775], [6.751575946807861], [6.149890899658203], [5.366613864898682], [5.846230506896973], [4.890763759613037], [5.339908599853516], [6.05285120010376], [5.072675704956055], [6.366183280944824], [7.1411848068237305], [5.1233930587768555], [5.579001426696777], [5.854236125946045], [7.209503650665283], [5.200780868530273], [5.7073564529418945], [7.168997764587402], [6.728938579559326], [5.112525939941406], [6.0460429191589355], [5.946784496307373], [4.813876152038574], [7.176907062530518], [5.932238578796387], [5.263430118560791], [5.683046340942383], [7.636188983917236], [5.886236190795898], [5.441524028778076], [6.493858814239502], [5.763578414916992], [6.901576519012451], [6.478003978729248], [6.670601844787598], [4.770111083984375], [6.375784873962402], [5.520668983459473], [6.446483135223389], [6.658846855163574], [7.087181091308594], [5.635869979858398], [5.892264366149902], [5.323873519897461], [6.552903175354004], [6.606447219848633], [5.547455787658691], [6.36210823059082], [6.9812211990356445], [6.613590240478516], [5.301383018493652], [5.260671138763428], [5.411514759063721], [5.96887731552124], [5.410876750946045], [5.2099080085754395], [8.008346557617188], [6.321288108825684], [5.809226036071777], [5.47139835357666], [4.830575942993164], [5.599196910858154], [5.954217910766602], [7.297226905822754], [6.081450462341309], [6.455422878265381], [4.951004505157471], [6.112268447875977], [4.931014060974121], [6.240998268127441], [4.515981197357178], [5.968301773071289], [6.184126853942871], [5.552786827087402], [5.36273193359375], [5.396728515625], [5.110904693603516], [6.048771381378174], [5.731205940246582], [5.837739944458008], [5.791984558105469], [5.678737640380859], [5.423489093780518], [5.248813152313232], [4.754818439483643], [6.655238151550293], [6.125820636749268], [5.473361015319824], [5.417229652404785], [6.06190824508667], [5.520995140075684], [6.139647006988525], [6.202803611755371], [6.361067295074463], [7.100295543670654], [5.047203540802002], [6.32558012008667], [6.11988639831543], [5.753435134887695], [6.437826633453369], [6.2860870361328125], [5.749576568603516], [5.709120273590088], [6.608354568481445], [5.434966564178467], [5.823714733123779], [6.951739311218262], [8.110648155212402], [5.333113670349121], [5.6565046310424805], [5.276492595672607], [5.861579895019531], [5.801919937133789], [6.376364707946777], [5.5680251121521], [6.849801063537598], [6.578613758087158], [5.884099006652832], [6.387991905212402], [6.065159797668457], [5.341792106628418], [4.941369533538818], [5.154245376586914], [9.482135772705078], [5.226489067077637], [7.351403713226318], [5.252511024475098], [5.350478649139404], [5.491260528564453], [6.705264568328857], [5.848796844482422], [5.913553714752197], [6.258739948272705], [5.28514289855957], [6.319061279296875], [6.148627281188965], [7.466388702392578], [5.609741687774658], [6.630153656005859], [5.178712844848633], [6.641796588897705], [6.025892734527588], [6.185079097747803], [6.710956573486328], [6.388072490692139], [5.665318489074707], [5.286520481109619], [7.159033298492432], [5.442678451538086], [8.21358871459961], [5.981802940368652], [5.63833475112915], [6.9513959884643555], [7.283458709716797], [5.9443135261535645], [5.720151424407959], [5.966629505157471], [7.343658447265625], [6.381359100341797], [5.958709239959717], [5.442221164703369], [6.00715446472168], [5.8667497634887695], [5.318607807159424], [6.5906291007995605], [5.286646366119385], [5.609431743621826], [7.290218830108643], [5.807343482971191], [6.337203025817871], [5.691984176635742], [7.216004371643066], [6.70760440826416], [6.462157726287842], [5.139723300933838], [6.61415958404541], [5.36273193359375], [6.137932300567627], [6.517039775848389], [7.405757427215576], [6.297691345214844], [5.183269500732422], [5.315739154815674], [5.3041815757751465], [5.383627891540527], [6.1473388671875], [5.499091148376465], [6.352238655090332], [5.279880046844482], [5.635730266571045], [6.3766560554504395], [4.9543046951293945], [5.261303901672363], [5.810348033905029], [5.941065788269043], [6.802059650421143], [5.936186790466309], [6.875441074371338], [5.092463493347168], [6.036845684051514], [6.319045066833496], [6.58505916595459], [6.130782127380371], [5.815943717956543], [6.2917985916137695], [5.348556041717529], [5.980693817138672], [6.449633598327637], [5.331042289733887], [6.264429569244385], [5.440892219543457], [4.924875259399414], [6.342648506164551], [5.146862030029297], [5.320652008056641], [5.123885154724121], [5.687952518463135], [5.3730149269104], [6.08093786239624], [6.440807342529297], [5.324407577514648], [5.572229385375977], [6.832451820373535], [5.767358303070068], [6.277965068817139], [5.7435431480407715], [6.3085198402404785], [6.736995220184326], [4.969106674194336], [6.519306659698486], [7.215787410736084], [5.5680251121521], [5.232107162475586], [7.3328328132629395], [5.409695148468018], [5.830871105194092], [5.860573768615723], [5.459019184112549], [6.028648853302002], [4.952810287475586], [6.350404739379883], [6.456114292144775], [5.394345283508301], [5.581355571746826], [6.29567813873291], [7.255373477935791], [5.780722618103027], [5.489747047424316], [6.601465225219727], [5.991730213165283], [5.932854652404785], [6.389099597930908], [5.270411014556885], [5.382311820983887], [6.587307453155518], [6.582946300506592], [4.999733924865723], [6.279506683349609], [6.814881324768066], [4.902575492858887], [6.7547607421875], [5.654485702514648], [7.195046901702881], [6.4801225662231445], [5.418105125427246], [5.415340423583984], [6.410371780395508], [6.684689998626709], [5.786746025085449], [4.865509510040283], [5.558595180511475], [4.491996765136719], [5.513277530670166], [5.810599327087402], [6.824851036071777], [6.832899570465088], [5.843125343322754], [5.45513916015625], [6.537440299987793], [4.86536979675293], [5.370525360107422], [6.040688991546631], [6.897294521331787], [5.892150402069092], [5.5828094482421875], [6.1226019859313965], [7.382692813873291], [5.926967620849609], [5.936776161193848], [6.974627494812012], [5.741959571838379], [4.822346210479736], [7.279624938964844], [6.409296989440918], [4.800440788269043], [4.937751293182373], [5.820245742797852], [5.385808944702148], [5.448071002960205], [6.163365364074707], [5.589563846588135], [5.970071315765381], [5.360631465911865], [5.540519714355469], [5.7487335205078125], [5.1250810623168945], [6.5290207862854], [5.75148868560791], [6.029980659484863], [5.694497108459473], [7.053298473358154], [5.6827239990234375], [4.936652660369873], [6.49365758895874], [5.731752872467041], [6.665927886962891], [7.210601329803467], [5.778831481933594], [5.110904693603516], [5.990619659423828], [4.904148578643799], [6.640285491943359], [5.104515552520752], [5.660165786743164], [6.635622024536133], [5.282341003417969], [5.837005138397217], [6.384920120239258], [5.666811466217041], [5.399031639099121], [6.922515869140625], [6.280094146728516], [5.060651779174805], [4.895729064941406], [6.103738784790039], [5.577886581420898], [5.459665298461914], [5.3807053565979], [5.235324859619141], [5.201202392578125], [5.081747055053711], [4.864390850067139], [4.853045463562012], [6.230344772338867], [5.321249008178711], [6.01397180557251], [5.444295883178711], [6.188830375671387], [5.881009101867676], [5.196616172790527], [11.326915740966797], [6.90184211730957], [5.482606410980225], [4.949997425079346], [5.4280877113342285], [5.726913928985596], [5.539434432983398], [6.409291744232178], [8.419347763061523], [7.320763111114502], [5.811184406280518], [5.191188812255859], [4.95857048034668], [6.670457363128662], [5.6674885749816895], [6.778032302856445], [5.2284674644470215], [6.022014141082764], [5.446683883666992], [5.566269397735596], [5.751020431518555], [5.583171367645264], [6.7641682624816895], [6.576912879943848], [5.232069492340088], [7.24467134475708], [6.443553924560547], [7.048905849456787], [7.711832523345947], [4.742035865783691], [5.685701370239258], [6.332132816314697], [5.672698020935059], [5.8730010986328125], [5.485936164855957], [6.1843156814575195], [5.488609313964844], [5.832915306091309], [5.961651802062988], [6.876012802124023], [4.90833854675293], [5.878137588500977], [5.949423313140869], [5.924685478210449], [5.56390380859375], [5.954603672027588], [5.955111503601074], [6.228033065795898], [5.399031639099121], [6.786888122558594], [6.7873334884643555], [5.197083473205566], [6.982530117034912], [5.990592002868652], [5.519968509674072], [5.556774139404297], [4.965460300445557], [6.213550567626953], [5.249670505523682], [5.695663928985596], [6.028711795806885], [6.036845684051514], [6.661960124969482], [5.267502784729004], [7.946911811828613], [5.653067588806152], [6.099534511566162], [7.112471103668213], [6.564370632171631], [5.631647109985352], [5.797316551208496], [5.335679531097412], [6.563225269317627], [5.846857070922852], [6.164417743682861], [6.308241367340088], [8.281810760498047], [5.705378532409668], [6.220917224884033], [5.941065788269043], [6.733455181121826], [6.303393363952637], [7.168797492980957], [6.190813064575195], [5.824826240539551], [6.023870468139648], [5.8277435302734375], [5.505104064941406], [6.027409553527832], [5.694613933563232], [5.558284759521484], [5.614713668823242], [6.833614349365234], [5.443153381347656], [5.668878555297852], [6.568737983703613], [5.235477924346924], [6.185079097747803], [5.121817588806152], [6.33481502532959], [6.794181823730469], [4.432290554046631], [5.318768501281738], [6.345738887786865], [5.879150390625], [5.45351505279541], [5.478017330169678], [6.359748840332031], [5.4745612144470215], [5.456776142120361], [5.8618364334106445], [5.418800354003906], [6.984170913696289], [6.454901695251465], [4.821796417236328], [5.5708441734313965], [4.989489555358887], [5.82106351852417], [5.425400733947754], [6.405819892883301], [5.783044338226318], [7.354125022888184], [6.367161273956299], [5.996598243713379], [5.992085933685303], [6.443553924560547], [5.751020431518555], [5.332561492919922], [4.567284107208252], [5.739307880401611], [5.919576644897461], [7.965699672698975], [6.977202415466309], [6.848758220672607], [5.729887962341309], [5.407469749450684], [6.370962142944336], [6.413689613342285], [5.175237655639648], [6.882190227508545], [5.4332499504089355], [6.465787410736084], [6.140991687774658], [5.1143717765808105], [5.6863322257995605], [7.049278259277344], [6.367095470428467], [5.09547758102417], [7.946911811828613], [5.59492301940918], [6.330257892608643], [6.0984272956848145], [5.627504825592041], [6.386504173278809], [6.469357013702393], [5.78685188293457], [5.590070724487305], [6.374493598937988], [5.643707275390625], [6.358220100402832], [5.830379009246826], [5.548212051391602], [5.615015029907227], [5.8213419914245605], [7.303961753845215], [7.442069053649902], [7.965699672698975], [5.280786037445068], [5.586761474609375], [6.592767715454102], [6.437480926513672], [5.062343597412109], [5.44146203994751], [5.402371406555176], [6.949261665344238], [5.668600559234619], [5.850537300109863], [7.53488302230835], [6.912322998046875], [5.226964473724365], [5.240506649017334], [5.231945514678955], [6.7799859046936035], [6.9468560218811035], [7.024748802185059], [5.237730026245117], [5.367987632751465], [5.878543376922607], [6.472296237945557], [5.89764404296875], [6.143960475921631], [4.458547592163086], [5.9857635498046875], [5.487374305725098], [6.350741863250732], [6.242136001586914], [5.281216621398926], [5.411873817443848], [5.979555606842041], [6.646285057067871], [5.010608196258545], [4.848052024841309], [5.683046340942383], [7.438797473907471], [5.887248992919922], [5.070440292358398], [5.4948954582214355], [6.766719818115234], [5.5810770988464355], [6.055595397949219], [6.849891185760498], [6.294750213623047], [5.343595027923584], [6.726924419403076], [6.581881999969482], [7.46801233291626], [5.533341884613037], [6.097820281982422], [5.293074607849121], [6.797098159790039], [6.830368518829346], [6.034574508666992], [5.2162065505981445], [6.620394706726074], [8.267279624938965], [5.228217124938965], [5.240508079528809], [6.586371898651123], [5.510817527770996], [5.2392988204956055], [6.216773509979248], [6.974759578704834], [5.804231643676758], [6.1180338859558105], [5.9618330001831055], [5.98785924911499], [6.885150909423828], [5.6251397132873535], [6.439085006713867], [6.192660331726074], [5.708220481872559], [5.240142822265625], [6.769221782684326], [5.178764343261719], [5.914011478424072], [5.3231611251831055], [6.332132816314697], [6.493531227111816], [6.238584518432617], [7.232987403869629], [6.178892612457275], [5.694589614868164], [5.792616844177246], [5.879556179046631], [5.587662220001221], [6.106564521789551], [6.025736331939697], [7.081869125366211], [5.429722785949707], [4.709969997406006], [6.5375213623046875], [5.236991882324219], [6.428484916687012], [5.257986068725586], [5.145994186401367], [5.3574090003967285], [6.049551963806152], [6.263589859008789], [5.7932634353637695], [5.2076311111450195], [5.114870071411133], [6.316447734832764], [5.498923301696777], [5.022647857666016], [5.763716697692871], [5.661103248596191], [5.637826919555664], [6.0875983238220215], [5.263019561767578], [6.88174295425415], [6.171469211578369], [5.574075222015381], [5.609795570373535], [5.026595115661621], [6.59745979309082], [6.694602966308594], [5.9470930099487305], [6.018387794494629], [5.076266288757324], [5.623764991760254], [7.612708568572998], [6.433128833770752], [6.274757385253906], [6.971665382385254], [6.129671096801758], [4.670580863952637], [5.026595115661621], [7.821997165679932], [5.308288097381592], [5.328958511352539], [6.226958751678467], [5.619688510894775], [5.548389434814453], [6.379688262939453], [6.736995220184326], [6.579529285430908], [5.289400577545166], [5.799078464508057], [5.193432331085205], [5.565809726715088], [6.024105548858643], [6.824732780456543], [6.079931259155273], [5.28149938583374], [6.119596004486084], [6.061739921569824], [5.757275581359863], [5.537588119506836], [6.610154628753662], [5.599299430847168], [5.79823112487793], [5.620891571044922], [5.780766010284424], [6.535838603973389], [7.725461959838867], [6.08750057220459], [6.62457275390625], [5.911765098571777], [6.370699405670166], [5.166779518127441], [6.387919902801514], [5.322932720184326], [5.178764343261719], [4.832142353057861], [6.3981032371521], [6.572793006896973], [7.52810001373291], [6.392016410827637], [5.725584983825684], [5.881546974182129], [5.902871608734131], [5.644565582275391], [6.101744651794434], [7.248737335205078], [5.263019561767578], [5.153220176696777], [6.194422721862793], [6.963667869567871], [5.930105209350586], [6.030646324157715], [6.272090911865234], [5.2200541496276855], [5.652419567108154], [7.181146144866943], [6.003223419189453], [5.858843803405762], [6.080811500549316], [5.755221843719482], [5.345860004425049], [4.922351837158203], [5.54788064956665], [5.38047456741333], [6.741090297698975], [6.186568260192871], [5.943309783935547], [5.459665298461914], [7.214564323425293], [6.134520530700684], [5.865492820739746], [5.279114246368408], [6.019596099853516], [5.290559768676758], [6.238584518432617], [5.591477394104004], [5.256531715393066], [5.123757839202881], [6.0460429191589355], [5.922576904296875], [6.439355373382568], [6.524381637573242], [5.936186790466309], [6.081000328063965], [6.116283416748047], [5.843280792236328], [5.834083557128906], [6.278618812561035], [6.027409553527832], [5.2456512451171875], [6.087940692901611], [5.763011932373047], [7.034724235534668], [5.3213887214660645], [6.40067720413208], [7.324188709259033], [8.574085235595703], [7.413135051727295], [5.788311958312988], [7.9357523918151855], [6.109502792358398], [5.112525939941406], [5.483060359954834], [6.543043613433838], [5.937530994415283], [6.116488933563232], [5.918274402618408], [5.385024547576904], [6.838224411010742], [4.935229301452637], [5.3231611251831055], [5.881546974182129], [5.679650783538818], [5.2482709884643555], [6.838497161865234], [5.879762649536133], [5.195367813110352], [7.015249729156494], [4.676645755767822], [5.119202136993408], [5.949995040893555], [5.564661979675293], [5.385481834411621], [4.81050968170166], [4.913144588470459], [5.409743785858154], [6.8193559646606445], [6.184430122375488], [6.949362754821777], [7.14730978012085], [6.0446672439575195], [4.596457481384277], [6.507839202880859], [7.967263698577881], [5.09546422958374], [6.93300199508667], [5.36839485168457], [5.770866394042969], [5.380710124969482], [6.235395908355713], [5.815943717956543], [6.156816482543945], [7.278049945831299], [6.101883888244629], [4.818198204040527], [5.651597023010254], [4.80204963684082], [6.060497760772705], [6.1442718505859375], [5.559597015380859], [5.570764064788818], [4.878451824188232], [5.897039890289307], [7.0930657386779785], [5.297524929046631], [5.661827564239502], [5.709733009338379], [5.798869609832764], [4.881772994995117], [5.830813884735107], [5.308187484741211], [6.027409553527832], [5.385517120361328], [6.084148406982422], [5.830533981323242], [4.954019069671631], [5.456103324890137], [5.651776313781738], [5.941065788269043], [6.518289566040039], [6.462157726287842], [5.411263942718506], [6.130997657775879], [5.061410427093506], [5.096887588500977], [6.768478870391846], [5.026341438293457], [5.559597015380859], [6.378641605377197], [5.659139633178711], [5.808107376098633], [6.637608051300049], [6.979613780975342], [5.787928104400635], [5.1486430168151855], [6.2012200355529785], [5.015895843505859], [5.978715419769287], [6.140281677246094], [5.173732280731201], [6.157910346984863], [6.294750213623047], [5.743317604064941], [5.674383640289307], [6.641091346740723], [6.994282245635986], [5.431695461273193], [5.075010776519775], [6.194008827209473], [6.592156887054443], [6.160366535186768], [5.296112060546875], [5.734857082366943], [4.9161553382873535], [5.787928104400635], [5.630620956420898], [6.162351131439209], [5.683046340942383], [6.079587936401367], [5.692435264587402], [5.818988800048828], [5.54185676574707], [5.355661392211914], [7.012721538543701], [7.526403903961182], [5.540519714355469], [4.912615776062012], [5.37019681930542], [4.665875434875488], [6.415643215179443], [6.058947563171387], [6.928479194641113], [5.483120918273926], [5.527917861938477], [4.812171459197998], [5.088159561157227], [5.6937761306762695], [5.494726181030273], [5.455876350402832], [4.7523722648620605], [5.3955841064453125], [5.411072731018066], [5.3690948486328125], [5.444988250732422], [5.246346473693848], [5.631288051605225], [6.073431491851807], [5.3881025314331055], [6.022015571594238], [4.48790979385376], [5.642556667327881], [6.543043613433838], [5.146455764770508], [7.036561012268066], [6.532451629638672], [5.679194450378418], [5.49917459487915], [6.516482353210449], [6.938759803771973], [6.1504225730896], [7.088573932647705], [5.719624996185303], [6.808431625366211], [5.614556312561035], [6.392304420471191], [5.11575984954834], [5.956625938415527], [6.951739311218262], [5.761565208435059], [6.332132339477539], [6.739630699157715], [6.0847487449646], [5.543729305267334], [5.575525283813477], [5.812681198120117], [5.509410381317139], [5.600641250610352], [4.973398208618164], [5.478143215179443], [6.380202293395996], [5.087210655212402], [5.560757637023926], [5.615015029907227], [6.712308883666992], [6.109846591949463], [5.509333610534668], [6.525871276855469], [6.139606952667236], [6.027409553527832], [5.844799995422363], [6.047157287597656], [5.689264297485352], [5.212946891784668], [5.5559868812561035], [5.100694179534912], [6.239980697631836], [5.35886812210083], [5.157128810882568], [5.415798187255859], [6.076251029968262], [5.927637100219727], [6.3401198387146], [6.507839202880859], [6.650218963623047], [6.864851951599121], [5.422888278961182], [5.802943229675293], [5.843707084655762], [6.185079097747803], [4.736522197723389], [5.031619071960449], [6.013406753540039], [6.485724449157715], [5.8408894538879395], [6.214235305786133], [6.650362014770508], [6.366916179656982], [6.705509185791016], [5.227972984313965], [5.42299222946167], [5.168293476104736], [6.40795373916626], [6.00216007232666], [5.8575263023376465], [6.180846214294434], [7.078639507293701], [5.101072311401367], [6.0312676429748535], [6.859841346740723], [4.528321743011475], [4.708061218261719], [6.052652359008789], [6.0411295890808105], [8.467729568481445], [5.383962631225586], [6.829520225524902], [5.1662139892578125], [5.979746341705322], [5.364727020263672], [6.036845684051514], [6.293858528137207], [5.166440486907959], [5.25773811340332], [5.645652770996094], [5.479413032531738], [6.351476669311523], [5.617271423339844], [6.206447601318359], [7.081881999969482], [7.091757297515869], [7.103772163391113], [7.215787410736084], [7.684810638427734], [6.613289833068848], [6.091886043548584], [5.83955192565918], [5.764275550842285], [7.220396995544434], [5.292913436889648], [5.3275556564331055], [6.780706882476807], [4.461373805999756], [6.036845684051514], [5.385517120361328], [6.1681389808654785], [5.585812568664551], [5.861565113067627], [7.505316257476807], [6.7681708335876465], [6.276296615600586], [4.648089408874512], [5.949289798736572], [6.622955799102783], [5.008588790893555], [6.523528099060059], [5.595065593719482], [6.111973762512207], [5.620891571044922], [5.730617523193359], [6.886106967926025], [5.985915660858154], [5.597042083740234], [5.808904647827148], [6.091300964355469], [5.639858245849609], [5.368137359619141], [5.26634407043457], [5.840641975402832], [6.704680442810059], [5.990482330322266], [6.237537860870361], [6.40126895904541], [6.0140228271484375], [6.893275737762451], [6.452648162841797], [4.787353038787842], [5.832915306091309], [5.394996643066406], [5.185527801513672], [6.5614118576049805], [6.839479446411133], [5.587045192718506], [5.199847221374512], [6.891297340393066], [6.482858180999756], [6.398208141326904], [7.093894004821777], [5.414186000823975]]}"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "model_uri = 'runs:/7a4e1b77a55443ca828507a7d311a8b0/model'\n",
    "\n",
    "# Replace INPUT_EXAMPLE with your own input example to the model\n",
    "# A valid input example is a data instance suitable for pyfunc prediction\n",
    "input_data = test_x\n",
    "\n",
    "# Verify the model with the provided input data using the logged dependencies.\n",
    "# For more details, refer to:\n",
    "# https://mlflow.org/docs/latest/models.html#validate-models-before-deployment\n",
    "mlflow.models.predict(\n",
    "    model_uri=model_uri,\n",
    "    input_data=input_data,\n",
    "    env_manager=\"local\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b29cfef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.7780304],\n",
       "       [7.0900574],\n",
       "       [6.6128654],\n",
       "       ...,\n",
       "       [6.398208 ],\n",
       "       [7.093894 ],\n",
       "       [5.414186 ]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "model_uri = 'runs:/7a4e1b77a55443ca828507a7d311a8b0/model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "loaded_model.predict(pd.DataFrame(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cedbf1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Wine-Quality'.\n",
      "Created version '1' of model 'Wine-Quality'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1746267949943, current_stage='None', description=None, last_updated_timestamp=1746267949943, name='Wine-Quality', run_id='7a4e1b77a55443ca828507a7d311a8b0', run_link=None, source='file:///media/saif/New%20Volume/GenomeArcDev/MLOps/MLops/MLflowStarter/2-MLproject/mlruns/195242204327695645/7a4e1b77a55443ca828507a7d311a8b0/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Register in the model registry\n",
    "mlflow.register_model(model_uri,\"Wine-Quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c2c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
